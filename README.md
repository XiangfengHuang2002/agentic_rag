# Agentic-RAG: 基于垂直领域知识库的自适应决策问答系统

本项目构建了一个针对高度垂直领域（Final Fantasy XIV Wiki）的智能体增强检索生成系统（Agentic RAG）。系统通过 LangGraph 编排工作流，利用 DeepSeek-R1 系列模型的逻辑推理能力，结合 BGE 重排模型与相似度阈值判定，实现了高可靠性、低幻觉的垂直领域知识问答。

## 1. 系统架构

项目采用模块化分层设计，确保各组件在垂直领域场景下的协同效率：

* **编排层 (Orchestration)**: 使用 LangGraph 构建状态机，管理从用户提问到最终输出的决策循环（Thought -> Action -> Observation）。
* **模型层 (LLM)**: 采用 `DeepSeek-R1-Distill-Qwen-7B`，利用其思维链能力完成决策节点的逻辑判定。
* **存储与检索层 (Retrieval)**:
  * **向量库**: ChromaDB。
  * **嵌入模型**: BAAI/bge-m3（多粒度语义编码）。
  * **重排模型**: BAAI/bge-reranker-v2-m3（二次精排，提升召回相关性）。


* **评测体系 (Evaluation)**: 集成 `evaluate` 库，通过 ROUGE-L 与 BERTScore 指标实现对生成答案的定量评估。

## 2. 工程难点与核心改进

### 2.1 针对私域术语的检索决策优化

* **问题**: 垂直领域（如游戏机制）包含大量非通用的专有名词。在 7B 级别模型理解不充分的情况下，传统的“查询改写（Query Rewriting）”策略极易导致语义漂移，使改写后的词汇脱离术语语境。
* **对策**: 采取了“决策门禁”策略而非“盲目改写”。通过 BGE-Reranker 的重排分值与向量空间相似度建立硬性阈值。Agent 根据这些客观指标判定检索质量，若无法获得高置信度上下文则拒绝回答或触发特定逻辑，而非通过改写引入噪声。

### 2.2 小参数量模型下的逻辑冗余控制

* **问题**: `DeepSeek-R1-Distill` 模型在推理时易产生冗长的内容，影响系统在复杂状态切换时的稳定性。
* **对策**: 通过精细化的 Prompt Engineering 强制约束模型输出格式，将复杂的思维链引导至具体的决策路径上，显著提升了 Agent 的执行效率。

### 2.3 检索必要性判定的可靠性提升

* **问题**: 纯 LLM 判定“是否需要检索”在面对垂直领域术语时准确率不足。
* **对策**: 系统以向量相似度与重排得分作为主要的硬性决策依据，仅在缺乏可用上下文时退化使用 LLM 进行判断。这种“逻辑推理 + 硬性指标”的混合决策机制，有效避免了模型在私域场景下产生的不稳定决策。

## 3. 技术演进与指标对比

所有实验版本在相同的检索配置（Top-K、Embedding 模型、Reranker）下进行对比，以保证性能差异主要来源于决策策略本身。

### 3.1 实验数据汇总

| 实验版本 | 测试问题 | ROUGE-L | BERTScore (F1) | 版本核心特征 |
| --- | --- | --- | --- | --- |
| **v0: Standard RAG Baseline** | Q1-Q3 | - | - | **对照组**：非 Agent 架构。系统对所有查询执行 Top-K 检索并生成答案，不包含自我修正。 |
| **v1: Agentic Base** | Q1 | 0.5714 | 0.6729 | 基础 ReAct 编排逻辑，依赖模型原生推理判定。 |
|  | Q2 | 0.1538 | 0.6043 |  |
|  | Q3 | 0.3000 | 0.6609 |  |
| **v2: Judgment System** | Q1 | 0.5714 | 0.6760 | 引入自动化评测反馈机制，增强对答案完整性的监控。 |
|  | Q2 | 0.0000 | 0.5522 | 反映出小参数模型在纯逻辑判定时的不稳定性。 |
|  | Q3 | 0.3478 | 0.7176 |  |
| **v3: Threshold Optimized** | Q1 | 0.5714 | **0.6903** | **核心策略：BGE 重排 + 向量相似度硬阈值准入。** |
|  | Q2 | 0.0000 | **0.6302** | 语义准确性显著回升，有效抑制模型幻觉。 |
|  | Q3 | 0.1538 | 0.6319 | 侧重于决策确定性，牺牲了冗余的字面匹配。 |

### 3.2 指标深度分析与选型权衡

1. **语义一致性下限的提升** v3 版本通过将相似度得分作为硬性门禁，显式约束了 Agent 的可回答空间。该策略在部分场景（如 Q3）中虽然降低了字面重合度（ROUGE-L），但显著提升了语义一致性下限（BERTScore），体现了系统在垂直领域下从“生成优先”向“决策确定性优先”的转变。
2. **工程判定 vs 逻辑推理** 实验证实，在小规模参数模型处理垂直领域数据时，基于相似度得分的硬门控（Gatekeeping）比基于生成的改写（Rewriting）更能保证知识问答的准确性。这为 RAG 系统在私域知识库落地提供了一种低成本、高鲁棒性的工程方案。

## 4. 项目结构

```text
agentic_rag/
├── docs_raw/               # 原始 Wiki 文本数据 (Raw Data)
├── docs_clean/             # 经过正则清洗后的文本数据 (Processed Data)
├── chroma_db/              # 持久化向量数据库 (BGE-M3 向量索引)
├── v0_baseline.ipynb       # 阶段0：基础 RAG 链路实现
├── v1_llm_judgment_qa.ipynb # 阶段1：引入 ReAct 逻辑与基础评测
├── v2_llm_judgment_full.ipynb # 阶段2：全量评测框架构建
├── v3_threshold_optimized_rag.ipynb # 阶段3：最终阈值优化与 Rerank 决策版
├── .env                    # 环境变量配置 (API Key)
├── requirements.txt        # 项目依赖清单
└── README.md               # 项目技术报告
```

## 5. 实验结论

通过对 Final Fantasy XIV 垂直领域知识库的实验分析，本项目得出以下核心结论：

1. **确定性优于生成覆盖**: 实验证实，在包含大量复杂私域术语（如特定技能名、副本机制）的场景下，LLM 贸然执行“查询改写”极易导致语义偏离用户原意。采用基于重排得分（BGE-Reranker Score）与向量相似度的硬门禁（Gatekeeping）策略，能有效约束 Agent 的可回答空间，从工程层面抑制了幻觉产生。
2. **语义一致性是核心指标**: 在垂直领域 RAG 的迭代中，单纯的文本重合度（ROUGE-L）无法完全反映系统质量。通过引入 BERTScore 并构建闭环评测流，本项目成功量化了 Agent 在逻辑一致性上的性能增益。

## 6. 环境配置

1. **依赖安装**:
```bash
pip install requests python-dotenv chromadb numpy bert-score evaluate rouge_score

```


2. **API 配置**:
在根目录创建 `.env` 文件并配置 `SILICONFLOW_API_KEY`。
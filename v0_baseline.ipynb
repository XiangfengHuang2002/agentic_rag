{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91de944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "SILICONFLOW_API_KEY = os.getenv(\"SILICONFLOW_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2504f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\t\"\"\"\n",
    "\t清理文本内容，去除Wiki标记和多余格式。\n",
    "\t\"\"\"\n",
    "\ttext = re.sub(r'\\{\\{对话\\|([^|]+)\\|([^}]+)\\}\\}', lambda m: f\"{m.group(1)}：{m.group(2).replace('<br>', ' ')}\", text)\n",
    "\n",
    "\ttext = re.sub(r'\\{\\{(?:xh|xl|状态|物品|任务|货币|版本|地图)\\|([^|}]*)[^}]*\\}\\}', r'\\1', text)\n",
    "\n",
    "\ttext = re.sub(r'\\{\\{Role\\|[^|]+\\|([^}]+)\\}\\}', r'\\1', text)\n",
    "\n",
    "\ttext = re.sub(r'\\{\\{[^}]+text=([^|}]+)[^}]*\\}\\}', r'\\1', text)\n",
    "\n",
    "\ttext = re.sub(r'\\{\\{黑幕\\|([^}]+)\\}\\}', r'\\1', text)\n",
    "\ttext = re.sub(r'<span[^>]*class=\"blackcover\"[^>]*>(.*?)</span>', r'\\1', text)\n",
    "\n",
    "\ttext = re.sub(r'\\[\\[(?:[^|\\]]+\\:)?([^|\\]]+\\|)?([^\\]]+)\\]\\]', lambda m: m.group(2) if m.group(2) else m.group(1).split('|')[0], text)\n",
    "\n",
    "\ttext = re.sub(r'<[^>]+>', '', text)\n",
    "\ttext = re.sub(r\"'''\", '', text) \n",
    "\ttext = re.sub(r\"''\", '', text)\n",
    "\n",
    "\ttext = re.sub(r'\\{\\{[^}]+\\}\\}', '', text)\n",
    "\n",
    "\ttext = re.sub(r'={2,}([^=]+)={2,}', r'\\1', text)\n",
    "\ttext = re.sub(r'^\\*+', '· ', text, flags=re.MULTILINE)\n",
    "\n",
    "\tlines = [line.strip() for line in text.splitlines() if line.strip()]\n",
    "\treturn \"\\n\".join(lines)\n",
    "\n",
    "def process_docs(input_dir, output_dir):\n",
    "\t\"\"\"\n",
    "\t处理输入目录中的所有文本文件，清理内容后保存到输出目录。\n",
    "\t\"\"\"\n",
    "\tif not os.path.exists(output_dir):\n",
    "\t\tos.makedirs(output_dir)\n",
    "\n",
    "\tfor filename in os.listdir(input_dir):\n",
    "\t\tif filename.endswith(\".txt\"):\n",
    "\t\t\twith open(os.path.join(input_dir, filename), 'r', encoding='utf-8') as f:\n",
    "\t\t\t\tcontent = f.read()\n",
    "\t\t\t\n",
    "\t\t\tclean_content = clean_text(content)\n",
    "\t\t\t\n",
    "\t\t\twith open(os.path.join(output_dir, filename), 'w', encoding='utf-8') as f:\n",
    "\t\t\t\tf.write(clean_content)\n",
    "\t\t\tprint(f\"成功清洗: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88d2dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功清洗: doc1.txt\n",
      "成功清洗: doc2.txt\n",
      "--- 清洗完成 ---\n"
     ]
    }
   ],
   "source": [
    "RAW_DIR = \"./docs_raw\"\n",
    "CLEAN_DIR = \"./docs_clean\"\n",
    "\n",
    "if os.path.exists(RAW_DIR):\n",
    "\tprocess_docs(RAW_DIR, CLEAN_DIR)\n",
    "\tprint(\"--- 清洗完成 ---\")\n",
    "else:\n",
    "\tprint(f\"错误: 找不到源文件夹 {RAW_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b161b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备向量化与 RAG 调用\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a81fb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "向量长度: 1024\n"
     ]
    }
   ],
   "source": [
    "# BGE-M3 向量化函数\n",
    "def get_embedding(text):\n",
    "\t\"\"\"调用 BGE-M3 获取文本向量\"\"\"\n",
    "\turl = \"https://api.siliconflow.cn/v1/embeddings\"\n",
    "\theaders = {\n",
    "\t\t\"Authorization\": f\"Bearer {SILICONFLOW_API_KEY}\",\n",
    "\t\t\"Content-Type\": \"application/json\"\n",
    "\t}\n",
    "\tpayload = {\n",
    "\t\t\"model\": \"BAAI/bge-m3\",\n",
    "\t\t\"input\": [text]\n",
    "\t}\n",
    "\tresp = requests.post(url, headers=headers, json=payload)\n",
    "\tdata = resp.json()\n",
    "\treturn data[\"data\"][0][\"embedding\"]\n",
    "\n",
    "# 测试\n",
    "sample_text = \"Agentic RAG 是结合检索与生成的系统\"\n",
    "vector = get_embedding(sample_text)\n",
    "print(f\"向量长度: {len(vector)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966c601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, min_len=100, max_len=1500):\n",
    "\t\"\"\"\n",
    "\t按换行符切分文本，每块长度控制在 min_len ~ max_len 之间。\n",
    "\t\n",
    "\t- min_len: 避免太短的段落\n",
    "\t- max_len: 避免超过模型 token 限制\n",
    "\t\"\"\"\n",
    "\tlines = [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "\tchunks = []\n",
    "\tcurrent_chunk = \"\"\n",
    "\t\n",
    "\tfor line in lines:\n",
    "\t\tif len(current_chunk) + len(line) + 1 <= max_len:\n",
    "\t\t\tcurrent_chunk += line + \"\\n\"\n",
    "\t\telse:\n",
    "\t\t\tif len(current_chunk) >= min_len:\n",
    "\t\t\t\tchunks.append(current_chunk.strip())\n",
    "\t\t\tcurrent_chunk = line + \"\\n\"\n",
    "\t\n",
    "\tif current_chunk.strip():\n",
    "\t\tchunks.append(current_chunk.strip())\n",
    "\t\n",
    "\treturn chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a8f9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到本地 ChromaDB，已包含 27 个向量，跳过构建\n"
     ]
    }
   ],
   "source": [
    "from chromadb import Client, PersistentClient\n",
    "from chromadb.config import Settings\n",
    "import os\n",
    "\n",
    "DB_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"text_chunks\"\n",
    "\n",
    "client = PersistentClient(path=DB_DIR)\n",
    "\n",
    "# 判断是否已有可用向量库\n",
    "db_exists = os.path.exists(DB_DIR)\n",
    "collection_names = [c.name for c in client.list_collections()]\n",
    "\n",
    "if db_exists and COLLECTION_NAME in collection_names:\n",
    "    collection = client.get_collection(name=COLLECTION_NAME)\n",
    "    if collection.count() > 0:\n",
    "        print(f\"检测到本地 ChromaDB，已包含 {collection.count()} 个向量，跳过构建\")\n",
    "    else:\n",
    "        print(\"集合存在但为空，开始构建向量库\")\n",
    "else:\n",
    "    print(\"未检测到本地向量库，开始构建\")\n",
    "\n",
    "# 只有在需要时才构建\n",
    "if not (db_exists and COLLECTION_NAME in collection_names and collection.count() > 0):\n",
    "    if COLLECTION_NAME in collection_names:\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "    else:\n",
    "        collection = client.create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "    for fname in os.listdir(CLEAN_DIR):\n",
    "        if not fname.endswith(\".txt\"):\n",
    "            continue\n",
    "\n",
    "        with open(os.path.join(CLEAN_DIR, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "        for i, chunk in enumerate(chunk_text(text)):\n",
    "            vec = get_embedding(chunk)\n",
    "            if vec is not None:\n",
    "                collection.add(\n",
    "                    ids=[f\"{fname}_part{i+1}\"],\n",
    "                    documents=[chunk],\n",
    "                    embeddings=[vec]\n",
    "                )\n",
    "\n",
    "    \n",
    "    print(f\"ChromaDB 向量库构建完成，共 {collection.count()} 个文档块\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2266f24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 文档: doc1.txt_part13\n",
      "Top-2 文档: doc1.txt_part18\n",
      "Top-3 文档: doc1.txt_part15\n",
      "Top-4 文档: doc1.txt_part16\n",
      "Top-5 文档: doc1.txt_part14\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# 检索 + BGE-Reranker 重排\n",
    "def retrieve(query, top_k=5):\n",
    "\tquery_vec = get_embedding(query)\n",
    "\t\n",
    "\t# ChromaDB 初步检索 top_k\n",
    "\tresults = collection.query(\n",
    "\t\tquery_embeddings=[query_vec],\n",
    "\t\tn_results=top_k\n",
    "\t)\n",
    "\t\n",
    "\t# 构建 top_docs\n",
    "\ttop_docs = []\n",
    "\tif results['documents']:\n",
    "\t\tfor doc_id, text in zip(results['ids'][0], results['documents'][0]):\n",
    "\t\t\ttop_docs.append({\n",
    "\t\t\t\t\"id\": doc_id,\n",
    "\t\t\t\t\"text\": text\n",
    "\t\t\t})\n",
    "\t\n",
    "\t# 调用 BGE-Reranker 进一步重排\n",
    "\turl = \"https://api.siliconflow.cn/v1/rerank\"\n",
    "\theaders = {\n",
    "\t\t\"Authorization\": f\"Bearer {SILICONFLOW_API_KEY}\",\n",
    "\t\t\"Content-Type\": \"application/json\"\n",
    "\t}\n",
    "\tpayload = {\n",
    "\t\t\"model\": \"BAAI/bge-reranker-v2-m3\",\n",
    "\t\t\"query\": query,\n",
    "\t\t\"documents\": [doc[\"text\"] for doc in top_docs]\n",
    "\t}\n",
    "\tresp = requests.post(url, headers=headers, json=payload)\n",
    "\tdata = resp.json()\n",
    "\t\n",
    "\tif \"results\" in data and data[\"results\"]:\n",
    "\t\t# 按相关性降序排序\n",
    "\t\tsorted_indices = [\n",
    "\t\t\titem[\"index\"] for item in sorted(\n",
    "\t\t\t\tdata[\"results\"],\n",
    "\t\t\t\tkey=lambda x: x[\"relevance_score\"],\n",
    "\t\t\t\treverse=True\n",
    "\t\t\t)\n",
    "\t\t]\n",
    "\t\treranked_docs = [top_docs[i] for i in sorted_indices]\n",
    "\telse:\n",
    "\t\treranked_docs = top_docs\n",
    "\n",
    "\treturn reranked_docs\n",
    "\n",
    "# 测试\n",
    "top_docs = retrieve(\"什么是 Agentic RAG？\")\n",
    "for i, doc in enumerate(top_docs):\n",
    "\tprint(f\"Top-{i+1} 文档: {doc['id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d4d6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成答案:\n",
      " **Agentic RAG**\n",
      "\n",
      "- **Agentic**: 主动的、控制的  \n",
      "- **RAG**: 可能指某种角色或技能组合  \n",
      "- 结合上下文，可能指一种战斗机制或技能组合，用于主动控制或触发特定效果\n"
     ]
    }
   ],
   "source": [
    "# 调用 DeepSeek-R1 生成答案\n",
    "def generate_answer(query, context_docs):\n",
    "\turl = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
    "\theaders = {\n",
    "\t\t\"Authorization\": f\"Bearer {SILICONFLOW_API_KEY}\",\n",
    "\t\t\"Content-Type\": \"application/json\"\n",
    "\t}\n",
    "\t\n",
    "\tcontext_text = \"\\n\".join([doc[\"text\"] for doc in context_docs])\n",
    "\tprompt = f\"\"\"\n",
    "请根据以下参考内容回答问题，只输出最终答案，不要输出任何思考过程或分析步骤。\n",
    "严格按照条列格式输出，禁止任何解释或推理。\n",
    "\n",
    "【参考内容】\n",
    "{context_text}\n",
    "\n",
    "【问题】\n",
    "{query}\n",
    "\n",
    "【要求】\n",
    "- 输出必须为 Markdown 条列形式，并且尽可能简洁\n",
    "- 不允许出现任何“我认为 / 首先 / 我需要思考 / 接下来 / 为了确认”等语言\n",
    "\"\"\"\n",
    "\t\n",
    "\tpayload = {\n",
    "\t\t\"model\": \"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B\",\n",
    "\t\t\"messages\": [\n",
    "\t\t\t{\n",
    "\t\t\t\t\"role\": \"system\",\n",
    "\t\t\t\t\"content\": \"你只输出最终答案，不输出任何思考过程。\"\n",
    "\t\t\t},\n",
    "\t\t\t{\n",
    "\t\t\t\t\"role\": \"user\",\n",
    "\t\t\t\t\"content\": prompt\n",
    "\t\t\t}\n",
    "\t\t],\n",
    "\t\t\"max_tokens\": 2000,\n",
    "\t\t\"temperature\": 0.2\n",
    "\t}\n",
    "\n",
    "\tresp = requests.post(url, headers=headers, json=payload)\n",
    "\tcontent = resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\t\n",
    "\tif \"</think>\" in content:\n",
    "\t\tanswer = content.split(\"</think>\")[-1].strip()\n",
    "\telse:\n",
    "\t\tanswer = content.strip()\n",
    "\t\n",
    "\treturn answer\n",
    "\n",
    "# 测试\n",
    "answer = generate_answer(\"什么是 Agentic RAG？\", top_docs)\n",
    "print(\"生成答案:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e2b63b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 答案:\n",
      " Agentic RAG的核心流程可能包括以下步骤：\n",
      "\n",
      "1. **初始化**：玩家或系统进入RAG环境，准备开始任务。\n",
      "2. **资源收集**：玩家通过探索、战斗或任务完成获得资源。\n",
      "3. **任务分配**：根据资源情况，系统或玩家决定执行的任务。\n",
      "4. **任务执行**：玩家或系统执行分配的任务，可能涉及战斗、资源利用等。\n",
      "5. **反馈与调整**：任务完成后，获得反馈并调整后续流程。\n",
      "\n",
      "以上流程基于常见机制的推测，具体细节可能因实际游戏或系统而异。\n"
     ]
    }
   ],
   "source": [
    "# 一步调用 RAG\n",
    "def rag_pipeline(query):\n",
    "\t# 1. 检索\n",
    "\ttop_docs = retrieve(query)\n",
    "\t# 2. 生成答案\n",
    "\tanswer = generate_answer(query, top_docs)\n",
    "\treturn answer\n",
    "\n",
    "# 测试\n",
    "query = \"Agentic RAG 的核心流程是什么？\"\n",
    "answer = rag_pipeline(query)\n",
    "print(\"RAG 答案:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5b879f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 答案:\n",
      " G17 6张 底30w 挂件v10  \n",
      "- G17：特定地图或副本  \n",
      "- 6张：6个相关道具或副本  \n",
      "- 底30w：底价30万金币  \n",
      "- 挂件v10：第10版本的挂件道具\n"
     ]
    }
   ],
   "source": [
    "query = \"‘G17 6张 底30w 挂件v10’是什么意思？\"\n",
    "answer = rag_pipeline(query)\n",
    "print(\"RAG 答案:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61348f89-fbf7-43b4-9b52-47c0be16a203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 答案:\n",
      " ### 月读极神的核心机制\n",
      "\n",
      "1. **极月读机制**：\n",
      "   - 在P3阶段，赋予玩家四层新月或满月。\n",
      "   - 场地被分为黑（新月）和白（满月）两色区域。\n",
      "   - 黑区域会积累怨念，导致死亡宣告。\n",
      "   - 白区域会附带15秒的出血和1秒的死亡宣告。\n",
      "\n",
      "2. **百月光机制**：\n",
      "   - 生成两个并排的月光释放范围可见的环形AOE。\n",
      "   - 百月光会在两个位置释放，且位置必定在月牙的中心。\n",
      "\n",
      "3. **深宵换装机制**：\n",
      "   - 第一次极月读的深宵换装必定为火枪。\n",
      "   - 第二次极月读的深宵换装必定为长枪。\n",
      "   - 月相属性相反，即第一次为新月，第二次为满月，或反之。\n"
     ]
    }
   ],
   "source": [
    "query = \"月读极神的核心机制是什么？\"\n",
    "answer = rag_pipeline(query)\n",
    "print(\"RAG 答案:\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a90839-8399-43dd-80c0-4e23e2052ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
